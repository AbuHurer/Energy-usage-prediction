{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8043ecb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\ttraining's rmse: 21.7152\tvalid_1's rmse: 23.0204\n",
      "[200]\ttraining's rmse: 20.9211\tvalid_1's rmse: 22.3599\n",
      "[300]\ttraining's rmse: 20.5745\tvalid_1's rmse: 22.2197\n",
      "[400]\ttraining's rmse: 20.3378\tvalid_1's rmse: 22.0093\n",
      "[500]\ttraining's rmse: 20.142\tvalid_1's rmse: 21.8593\n",
      "[600]\ttraining's rmse: 19.9937\tvalid_1's rmse: 21.7326\n",
      "[700]\ttraining's rmse: 19.904\tvalid_1's rmse: 21.7027\n",
      "[800]\ttraining's rmse: 19.8207\tvalid_1's rmse: 21.6904\n",
      "Early stopping, best iteration is:\n",
      "[755]\ttraining's rmse: 19.8523\tvalid_1's rmse: 21.6493\n",
      "RMSE: 21.6493\n",
      "RÂ² Score: 0.9657\n",
      "         actual_usage  predicted_usage\n",
      "Regions                               \n",
      "ER          65.448141        64.254990\n",
      "NER          5.734615         5.767246\n",
      "NR         112.003859       112.655754\n",
      "SR         163.135342       164.839596\n",
      "WR         184.959804       185.980177\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"long_data_.csv\")\n",
    "\n",
    "# ====== Target Variable ======\n",
    "target = \"Usage\"\n",
    "\n",
    "# ====== Handle Dates ======\n",
    "df[\"Dates\"] = pd.to_datetime(df[\"Dates\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"Dates\"].dt.year\n",
    "df[\"month\"] = df[\"Dates\"].dt.month\n",
    "df[\"day\"] = df[\"Dates\"].dt.day\n",
    "df = df.drop(columns=[\"Dates\"])  # drop raw datetime\n",
    "\n",
    "# ====== Handle Categorical Columns ======\n",
    "categorical_cols = []\n",
    "for col in [\"States\", \"Regions\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "# ====== Features & Target ======\n",
    "X = df.drop(columns=[target])\n",
    "y = df[target]\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# LightGBM Dataset\n",
    "train_data = lgb.Dataset(\n",
    "    X_train, label=y_train, categorical_feature=categorical_cols, free_raw_data=False\n",
    ")\n",
    "test_data = lgb.Dataset(\n",
    "    X_test, label=y_test, categorical_feature=categorical_cols, free_raw_data=False\n",
    ")\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"rmse\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Train with callbacks\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    valid_sets=[train_data, test_data],\n",
    "    num_boost_round=1000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(stopping_rounds=50),\n",
    "        lgb.log_evaluation(period=100)\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Predictions\n",
    "y_pred = model.predict(X_test, num_iteration=model.best_iteration)\n",
    "\n",
    "# Evaluation\n",
    "import numpy as np\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")\n",
    "print(f\"RÂ² Score: {r2:.4f}\")\n",
    "\n",
    "# Region-wise prediction summary\n",
    "if \"Regions\" in df.columns:\n",
    "    region_preds = X_test.copy()\n",
    "    region_preds[\"actual_usage\"] = y_test\n",
    "    region_preds[\"predicted_usage\"] = y_pred\n",
    "    print(region_preds.groupby(\"Regions\")[[\"actual_usage\", \"predicted_usage\"]].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa305f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Dates  States Regions   latitude  longitude  year  month  day  \\\n",
      "0  2020-05-13  Punjab      NR  31.519974  75.980003  2020      5   13   \n",
      "1  2020-05-14  Punjab      NR  31.519974  75.980003  2020      5   14   \n",
      "2  2020-05-15  Punjab      NR  31.519974  75.980003  2020      5   15   \n",
      "3  2020-05-16  Punjab      NR  31.519974  75.980003  2020      5   16   \n",
      "4  2020-05-17  Punjab      NR  31.519974  75.980003  2020      5   17   \n",
      "5  2020-05-18  Punjab      NR  31.519974  75.980003  2020      5   18   \n",
      "6  2020-05-19  Punjab      NR  31.519974  75.980003  2020      5   19   \n",
      "7  2020-05-20  Punjab      NR  31.519974  75.980003  2020      5   20   \n",
      "8  2020-05-21  Punjab      NR  31.519974  75.980003  2020      5   21   \n",
      "9  2020-05-22  Punjab      NR  31.519974  75.980003  2020      5   22   \n",
      "10 2020-05-23  Punjab      NR  31.519974  75.980003  2020      5   23   \n",
      "11 2020-05-24  Punjab      NR  31.519974  75.980003  2020      5   24   \n",
      "12 2020-05-25  Punjab      NR  31.519974  75.980003  2020      5   25   \n",
      "13 2020-05-26  Punjab      NR  31.519974  75.980003  2020      5   26   \n",
      "14 2020-05-27  Punjab      NR  31.519974  75.980003  2020      5   27   \n",
      "15 2020-05-28  Punjab      NR  31.519974  75.980003  2020      5   28   \n",
      "16 2020-05-29  Punjab      NR  31.519974  75.980003  2020      5   29   \n",
      "17 2020-05-30  Punjab      NR  31.519974  75.980003  2020      5   30   \n",
      "18 2020-05-31  Punjab      NR  31.519974  75.980003  2020      5   31   \n",
      "19 2020-06-01  Punjab      NR  31.519974  75.980003  2020      6    1   \n",
      "\n",
      "    dayofweek  is_weekend  predicted_usage  \n",
      "0           2           0       153.870827  \n",
      "1           3           0       137.864773  \n",
      "2           4           0       144.775182  \n",
      "3           5           1       157.971598  \n",
      "4           6           1       173.510273  \n",
      "5           0           0       140.065013  \n",
      "6           1           0       145.877628  \n",
      "7           2           0       153.870827  \n",
      "8           3           0       137.864773  \n",
      "9           4           0       144.775182  \n",
      "10          5           1       157.971598  \n",
      "11          6           1       173.510273  \n",
      "12          0           0       140.065013  \n",
      "13          1           0       145.877628  \n",
      "14          2           0       153.870827  \n",
      "15          3           0       137.864773  \n",
      "16          4           0       144.775182  \n",
      "17          5           1       157.971598  \n",
      "18          6           1       173.510273  \n",
      "19          0           0       153.692330  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<lightgbm.basic.Booster at 0x1ef7dc0f910>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"long_data_.csv\")\n",
    "\n",
    "# ====== Target Variable ======\n",
    "target = \"Usage\"\n",
    "\n",
    "# ====== Handle Dates ======\n",
    "df[\"Dates\"] = pd.to_datetime(df[\"Dates\"], errors=\"coerce\")\n",
    "df[\"year\"] = df[\"Dates\"].dt.year\n",
    "df[\"month\"] = df[\"Dates\"].dt.month\n",
    "df[\"day\"] = df[\"Dates\"].dt.day\n",
    "df[\"dayofweek\"] = df[\"Dates\"].dt.dayofweek\n",
    "df[\"is_weekend\"] = (df[\"Dates\"].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "# ====== Handle Categorical Columns ======\n",
    "categorical_cols = []\n",
    "for col in [\"States\", \"Regions\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(\"category\")\n",
    "        categorical_cols.append(col)\n",
    "\n",
    "# ====== Features & Target ======\n",
    "X = df.drop(columns=[target, \"Dates\"])\n",
    "y = df[target]\n",
    "\n",
    "# LightGBM Dataset (use all data for training)\n",
    "train_data = lgb.Dataset(\n",
    "    X, label=y, categorical_feature=categorical_cols, free_raw_data=False\n",
    ")\n",
    "\n",
    "# Parameters\n",
    "params = {\n",
    "    \"objective\": \"regression\",\n",
    "    \"metric\": [\"rmse\"],\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"num_leaves\": 31,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"feature_fraction\": 0.9,\n",
    "    \"bagging_fraction\": 0.8,\n",
    "    \"bagging_freq\": 5,\n",
    "    \"verbose\": -1\n",
    "}\n",
    "\n",
    "# Train full model\n",
    "model = lgb.train(\n",
    "    params,\n",
    "    train_data,\n",
    "    num_boost_round=500\n",
    ")\n",
    "\n",
    "# ===============================\n",
    "# ðŸ”® Predict Future Dates\n",
    "# ===============================\n",
    "\n",
    "# Generate next 90 days (example)\n",
    "future_dates = pd.date_range(df[\"Dates\"].max() + pd.Timedelta(days=1), periods=1825, freq=\"D\")\n",
    "future_df = pd.DataFrame({\"Dates\": future_dates})\n",
    "\n",
    "# Expand to all regions (so every region gets prediction for each future date)\n",
    "regions = df[\"Regions\"].unique()\n",
    "states = df[\"States\"].unique()\n",
    "\n",
    "future_full = []\n",
    "for region in regions:\n",
    "    for state in df.loc[df[\"Regions\"] == region, \"States\"].unique():\n",
    "        temp = future_df.copy()\n",
    "        temp[\"States\"] = state\n",
    "        temp[\"Regions\"] = region\n",
    "        # Use stateâ€™s lat/long (taking mean if multiple rows)\n",
    "        lat = df.loc[df[\"States\"] == state, \"latitude\"].mean()\n",
    "        lon = df.loc[df[\"States\"] == state, \"longitude\"].mean()\n",
    "        temp[\"latitude\"] = lat\n",
    "        temp[\"longitude\"] = lon\n",
    "        future_full.append(temp)\n",
    "\n",
    "future_full = pd.concat(future_full, ignore_index=True)\n",
    "\n",
    "# Extract date features\n",
    "future_full[\"year\"] = future_full[\"Dates\"].dt.year\n",
    "future_full[\"month\"] = future_full[\"Dates\"].dt.month\n",
    "future_full[\"day\"] = future_full[\"Dates\"].dt.day\n",
    "future_full[\"dayofweek\"] = future_full[\"Dates\"].dt.dayofweek\n",
    "future_full[\"is_weekend\"] = (future_full[\"Dates\"].dt.dayofweek >= 5).astype(int)\n",
    "\n",
    "# Encode categorical\n",
    "for col in [\"States\", \"Regions\"]:\n",
    "    future_full[col] = future_full[col].astype(\"category\")\n",
    "\n",
    "# Drop Dates for prediction\n",
    "X_future = future_full.drop(columns=[\"Dates\"])\n",
    "\n",
    "# Predict usage\n",
    "future_full[\"predicted_usage\"] = model.predict(X_future)\n",
    "\n",
    "print(future_full.head(20))  # Show first 20 predictions\n",
    "model.save_model(\"energy_usage_model.txt\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
